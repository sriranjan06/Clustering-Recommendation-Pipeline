{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**CSE 572: Data Mining Homework 3**</center>\n",
    "**Name: Sriranjan Srikanth** <br>\n",
    "**ASU ID: 1229309109**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 1: K-Means Clustering**\n",
    "This task involves implementing the K-Means clustering algorithm from scratch using three distance metrics:\n",
    "1. Euclidean Distance\n",
    "2. 1 - Cosine Similarity\n",
    "3. 1 - Generalized Jaccard Similarity\n",
    "\n",
    "We will analyze the performance of these metrics based on SSE, accuracy, and convergence criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   778  779  780  781  782  783  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 784 columns]\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 784 entries, 0 to 783\n",
      "dtypes: int64(784)\n",
      "memory usage: 59.8 MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "779    0\n",
      "780    0\n",
      "781    0\n",
      "782    0\n",
      "783    0\n",
      "Length: 784, dtype: int64\n",
      "Number of Clusters (K): 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "data = pd.read_csv('kmeans_data/data.csv', header=None)  # 10000 samples, 784 features\n",
    "labels = pd.read_csv('kmeans_data/label.csv', header=None)  # Ground-truth labels\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(data.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Define the number of clusters (K) based on the labels\n",
    "K = labels[0].nunique()  # There are 10 unique labels\n",
    "print(f\"Number of Clusters (K): {K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **K-Means Implementation**\n",
    "Below, we implement the K-Means clustering algorithm from scratch. This includes:\n",
    "- Distance functions for Euclidean, 1 - Cosine Similarity, and 1 - Generalized Jaccard Similarity.\n",
    "- Functions to initialize centroids, assign clusters, and update centroids.\n",
    "- A main function to perform K-Means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Euclidean distance\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# 1 - Cosine similarity\n",
    "def cosine_similarity(x, y):\n",
    "    cos_sim = np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "    return 1 - cos_sim\n",
    "\n",
    "# 1 - Generalized Jaccard similarity\n",
    "def jaccard_similarity(x, y):\n",
    "    intersection = np.sum(np.minimum(x, y))\n",
    "    union = np.sum(np.maximum(x, y))\n",
    "    return 1 - (intersection / union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize centroids\n",
    "def initialize_centroids(data, K):\n",
    "    return data.sample(n=K).to_numpy()\n",
    "\n",
    "# Assign clusters based on the selected distance function\n",
    "def assign_clusters(data, centroids, distance_fn):\n",
    "    clusters = []\n",
    "    for _, point in data.iterrows():\n",
    "        distances = [distance_fn(point.to_numpy(), centroid) for centroid in centroids]\n",
    "        clusters.append(np.argmin(distances))\n",
    "    return np.array(clusters)\n",
    "\n",
    "# Update centroids based on cluster assignments\n",
    "def update_centroids(data, clusters, K):\n",
    "    new_centroids = []\n",
    "    for k in range(K):\n",
    "        cluster_points = data[clusters == k]\n",
    "        new_centroids.append(cluster_points.mean(axis=0))\n",
    "    return np.array(new_centroids)\n",
    "\n",
    "# Check for convergence\n",
    "def has_converged(old_centroids, new_centroids):\n",
    "    return np.allclose(old_centroids, new_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main K-Means algorithm\n",
    "def kmeans(data, K, distance_fn, max_iters=100):\n",
    "    centroids = initialize_centroids(data, K)\n",
    "    for i in range(max_iters):\n",
    "        clusters = assign_clusters(data, centroids, distance_fn)\n",
    "        new_centroids = update_centroids(data, clusters, K)\n",
    "        \n",
    "        # Check stopping criteria\n",
    "        if has_converged(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return clusters, centroids\n",
    "\n",
    "# Compute SSE\n",
    "def compute_sse(data, clusters, centroids):\n",
    "    sse = 0\n",
    "    for k in range(len(centroids)):\n",
    "        cluster_points = data[clusters == k]\n",
    "        sse += np.sum((cluster_points - centroids[k]) ** 2)\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Running K-Means with Different Distance Metrics**\n",
    "We now run the K-Means algorithm using:\n",
    "1. Euclidean Distance\n",
    "2. 1 - Cosine Similarity\n",
    "3. 1 - Generalized Jaccard Similarity\n",
    "\n",
    "We will compute and compare the SSE for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE Results:\n",
      "Euclidean: 25437047258.18773\n",
      "Cosine: 25484251221.48815\n",
      "Jaccard: 25416818402.689133\n"
     ]
    }
   ],
   "source": [
    "# Convert data to NumPy array for processing\n",
    "features = data.to_numpy()\n",
    "\n",
    "# Run K-Means for each distance metric\n",
    "clusters_euclidean, centroids_euclidean = kmeans(data, K, euclidean_distance)\n",
    "clusters_cosine, centroids_cosine = kmeans(data, K, cosine_similarity)\n",
    "clusters_jaccard, centroids_jaccard = kmeans(data, K, jaccard_similarity)\n",
    "\n",
    "# Compute SSE for each method\n",
    "sse_euclidean = compute_sse(features, clusters_euclidean, centroids_euclidean)\n",
    "sse_cosine = compute_sse(features, clusters_cosine, centroids_cosine)\n",
    "sse_jaccard = compute_sse(features, clusters_jaccard, centroids_jaccard)\n",
    "\n",
    "# Print SSE Results\n",
    "print(\"SSE Results:\")\n",
    "print(f\"Euclidean: {sse_euclidean}\")\n",
    "print(f\"Cosine: {sse_cosine}\")\n",
    "print(f\"Jaccard: {sse_jaccard}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cluster Evaluation and Analysis**\n",
    "\n",
    "1. Majority Vote Labeling\n",
    "- We label each cluster using the majority vote of the ground-truth labels in `label.csv`. This step allows us to evaluate the clustering accuracy for each distance metric.\n",
    "\n",
    "2. Predictive Accuracy\n",
    "- For each clustering method (Euclidean, Cosine, and Jaccard), we compute the predictive accuracy as the percentage of correctly labeled data points.\n",
    "\n",
    "3. Iterations and Convergence Analysis <br>\n",
    "- We analyze the number of iterations and time required for convergence under different stopping criteria:\n",
    "    - No change in centroid position.\n",
    "    - Increase in SSE in the next iteration.\n",
    "    - Maximum number of iterations (e.g., 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Results:\n",
      "Euclidean: 60.32%\n",
      "Cosine: 64.30%\n",
      "Jaccard: 60.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to label clusters using majority voting\n",
    "def majority_vote_labeling(clusters, labels, K):\n",
    "    cluster_labels = np.zeros(K)\n",
    "    for k in range(K):\n",
    "        # Extract ground-truth labels of points in the current cluster\n",
    "        cluster_points = labels[clusters == k]\n",
    "        # Assign the majority label to the cluster\n",
    "        if len(cluster_points) > 0:\n",
    "            cluster_labels[k] = np.bincount(cluster_points).argmax()\n",
    "    return cluster_labels\n",
    "\n",
    "# Function to calculate predictive accuracy\n",
    "def compute_accuracy(clusters, cluster_labels, true_labels):\n",
    "    predicted_labels = cluster_labels[clusters]\n",
    "    return accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Perform majority vote labeling for each clustering method\n",
    "true_labels = labels.to_numpy().flatten()\n",
    "cluster_labels_euclidean = majority_vote_labeling(clusters_euclidean, true_labels, K)\n",
    "cluster_labels_cosine = majority_vote_labeling(clusters_cosine, true_labels, K)\n",
    "cluster_labels_jaccard = majority_vote_labeling(clusters_jaccard, true_labels, K)\n",
    "\n",
    "# Compute predictive accuracy for each method\n",
    "accuracy_euclidean = compute_accuracy(clusters_euclidean, cluster_labels_euclidean, true_labels)\n",
    "accuracy_cosine = compute_accuracy(clusters_cosine, cluster_labels_cosine, true_labels)\n",
    "accuracy_jaccard = compute_accuracy(clusters_jaccard, cluster_labels_jaccard, true_labels)\n",
    "\n",
    "# Print Accuracy Results\n",
    "print(\"Accuracy Results:\")\n",
    "print(f\"Euclidean: {accuracy_euclidean * 100:.2f}%\")\n",
    "print(f\"Cosine: {accuracy_cosine * 100:.2f}%\")\n",
    "print(f\"Jaccard: {accuracy_jaccard * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration and Convergence Analysis**\n",
    "We analyze the iterations and convergence criteria for each distance metric:\n",
    "1. **Stopping Criteria:**\n",
    "   - No change in centroid position.\n",
    "   - SSE increases in the next iteration.\n",
    "   - Maximum number of iterations (e.g., 100).\n",
    "2. **Iterations and Convergence Time:**\n",
    "   - Count the number of iterations taken for each method.\n",
    "   - Measure the total execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations and Convergence Time:\n",
      "Euclidean - Iterations: 100, Time: 50.90 seconds\n",
      "Cosine - Iterations: 91, Time: 54.23 seconds\n",
      "Jaccard - Iterations: 79, Time: 55.11 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Modified K-Means to track iterations and time\n",
    "def kmeans_with_metrics(data, K, distance_fn, max_iters=100):\n",
    "    centroids = initialize_centroids(data, K)\n",
    "    iterations = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        iterations += 1\n",
    "        clusters = assign_clusters(data, centroids, distance_fn)\n",
    "        new_centroids = update_centroids(data, clusters, K)\n",
    "        \n",
    "        # Stopping criteria\n",
    "        if has_converged(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return clusters, centroids, iterations, elapsed_time\n",
    "\n",
    "# Run K-Means with metrics for each distance function\n",
    "_, _, iters_euclidean, time_euclidean = kmeans_with_metrics(data, K, euclidean_distance)\n",
    "_, _, iters_cosine, time_cosine = kmeans_with_metrics(data, K, cosine_similarity)\n",
    "_, _, iters_jaccard, time_jaccard = kmeans_with_metrics(data, K, jaccard_similarity)\n",
    "\n",
    "# Print Iteration and Time Results\n",
    "print(\"Iterations and Convergence Time:\")\n",
    "print(f\"Euclidean - Iterations: {iters_euclidean}, Time: {time_euclidean:.2f} seconds\")\n",
    "print(f\"Cosine - Iterations: {iters_cosine}, Time: {time_cosine:.2f} seconds\")\n",
    "print(f\"Jaccard - Iterations: {iters_jaccard}, Time: {time_jaccard:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
